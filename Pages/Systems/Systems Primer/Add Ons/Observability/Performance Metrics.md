1. Time to first Byte -TTFB measures the time taken from the moment a client sends a request to a server until the client receives the first byte of data from the server. It is an indicator of server responsiveness and network latency. Example: A website’s TTFB is 200 milliseconds, indicating a fast initial response from the server.
2. latency - It is a measure of the delay experienced in a system. Example: The time taken for a user’s request to reach a server and receive a response is 100 milliseconds.
3.  Throughput - Throughput measures the number of operations or requests processed by a system per unit of time. It is an indicator of the system’s capacity to handle workloads. Example: An API handling 500 requests per second.
4. Response Time - Total time to process request.  It helps in assessing the system’s efficiency in handling user requests. Example: A database query takes 250 milliseconds to complete, including 50 milliseconds spent in the queue.
5. Error Rate - Percentage of requests resulting in errors
6. Mean Time between failures - MTBF - MTBF is the average time between system failures or disruptions. It is an indicator of system reliability and the effectiveness of maintenance procedures. Example: A server has an MTBF of 30,000 hours, which means it is expected to operate without failure for an average of 30,000 hours.
7. Mean time to repair - MTTR - MTTR measures the average time taken to repair or recover from a system failure. A lower MTTR indicates a more efficient recovery process and reduced downtime. Example: A system has an MTTR of 2 hours, indicating that it takes an average of 2 hours to restore operations after a failure.
8. N/W Bandwidth - Network bandwidth is the maximum rate of data transfer across a network connection. It is an essential metric for evaluating network performance and determining potential bottlenecks. Example: A network connection with a bandwidth of 100 Mbps can transfer 100 megabits of data per second.
9. Request Rate - Number of requests received per unit of time
10. Concurrent Connections - Concurrent connections represent the number of active connections to a system at a given moment. This metric helps assess the system’s capacity to handle multiple simultaneous requests. Example: A database server can handle 5,000 concurrent connections without performance degradation.
11. Cache hit ratio - Cache hit ratio is the percentage of cache accesses that result in a cache hit, indicating that the requested data is found in the cache. A higher cache hit ratio suggests better cache efficiency and faster response times. Example: A cache with a 90% hit ratio successfully serves 9 out of 10 requests from the cache.
12. SLA Compliance - SLA compliance is the percentage of time that a system meets its predefined performance and availability objectives. A higher SLA compliance rate indicates better system performance and customer satisfaction. Example: A cloud service provider maintains 99.95% SLA compliance, meaning it meets its performance targets 99.95% of the time.
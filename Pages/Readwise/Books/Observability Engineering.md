# Observability Engineering

![rw-book-cover](https://m.media-amazon.com/images/I/81fuzyAMQ8L._SY160.jpg)

## Metadata
- Author: [[Charity Majors, Liz Fong-Jones, and George Miranda]]
- Full Title: Observability Engineering
- Category: #books

## Highlights
- In control theory, observability is defined as a measure of how well internal states of a system can be inferred from knowledge of its external outputs. ([Location 253](https://readwise.io/to_kindle?action=open&asin=B09ZQ6FHTT&location=253))
- For a software application to have observability, you must be able to do the following: Understand the inner workings of your application Understand any system state your application may have gotten itself into, even new ones you have never seen before and couldn’t have predicted Understand the inner workings and system state solely by observing and interrogating with external tools Understand the internal state without shipping any new custom code to handle it (because that implies you needed prior knowledge to explain it) A good litmus test for determining whether those conditions are true is to ask yourself the following questions: Can you continually answer open-ended questions about the inner workings of your applications to explain any anomalies, without hitting investigative dead ends (i.e., the issue might be in a certain group of things, but you can’t break it down any further to confirm)? Can you understand what any particular user of your software may be experiencing at any given time? Can you quickly see any cross-section of system performance you care about, from top-level aggregate views, down to the single and exact user requests that may be contributing to any slowness (and anywhere in between)? Can you compare any arbitrary groups of user requests in ways that let you correctly identify which attributes are commonly shared by all users who are experiencing unexpected behavior in your application? Once you do find suspicious attributes within one individual user request, can you search across all user requests to identify similar behavioral patterns to confirm or rule out your suspicions? Can you identify which system user is generating the most load (and therefore slowing application performance the most), as well as the 2nd, 3rd, or 100th most load-generating users? Can you identify which of those most-load-generating users only recently started impacting performance? If the 142nd slowest user complained about performance speed, can you isolate their requests to understand why exactly things are slow for that specific user? If users complain about timeouts happening, but your graphs show that the 99th, 99.9th, even 99.99th percentile requests are fast, can you find the hidden timeouts? Can you answer questions like the preceding ones without first needing to predict that you might need to ask them someday (and therefore set up specific monitors in advance to aggregate the necessary data)? Can you answer questions like these about your applications even if you have never seen or debugged this particular issue before? Can you get answers to questions like the preceding ones quickly, so that you can iteratively ask a new question, and another, and another, until you get to the correct source of issues, without losing your train of thought (which typically means getting answers within seconds instead of minutes)? Can you answer questions like the preceding ones even if that particular issue has never happened before? Do the results… ([Location 266](https://readwise.io/to_kindle?action=open&asin=B09ZQ6FHTT&location=266))
    - Tags: [[orange]] 
